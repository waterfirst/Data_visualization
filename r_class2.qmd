---
title: "Untitled"
format: html
editor: visual
---


## 4. 머신러닝

### 회귀(regression) : 펭귄부리 높이

```         
1. penquin 데이터의 행번호를 id 열로 만들어라 (mutate)  

2. penquin 데이터의 1행~300행까지 데이터를 train으로 만들고, bill_depth 열을 제외하고 X_train, id와 bill_depth 열을 이용하여 y_train을 만들어라  

3. penquin 데이터의 300행~마지막행까지  데이터를 test 로 만들고, bill_depth 열을 제외하고 y_train, id와 bill_depth 열을 이용하여 y_test을 만들어라.     

4. X_train, y_train 으로 모델링을 한 후, X_test를 이용하여 y_test의 bill_depth를 예측하라.

5. 예측한 값을 "수험번호.csv" 파일로 제출하라.
```

-   패키지 불러오기

```{r}
library(dplyr)
library(caret)
library(ModelMetrics)
library(randomForest)
library(palmerpenguins)


```

-   데이터 불러오기

```{r}
## 데이터 불러오기 (실제 시험장에서는 아래와 같이 간단하게 불러옴)

#X_train <- read.csv("../input/.../X_train.csv", stringsAsFactors=T)
#y_train <- read.csv("../input/.../y_train.csv", stringsAsFactors=T)

#X_test <- read.csv("../input/.../X_test.csv", stringsAsFactors=T)
#y_test <- read.csv("../input/.../y_test.csv", stringsAsFactors=T)

#penquin 데이터를 이용하여 데이터 train, test 데이터 만들기

penguins <- penguins %>% mutate(id=1:nrow(penguins)) |> 
  rename(bill_depth = bill_depth_mm,
         bill_length = bill_length_mm ,
         flipper_length  = flipper_length_mm,
         body_mass  = body_mass_g )

X_train <- penguins[1:300, -4]
y_train <- penguins[1:300, c(4,9)]
X_test <- penguins[301:344, -4]
y_test <- penguins[301:344, c(4,9)]
y_test[,1] <- 0
```

-   데이터 합치기

```{r}
train<-inner_join(y_train, X_train, by="id")

str(train)
str(X_test)

```

-   불필요한 컬럼 제거하기

```{r}
# id 열 제거하기
train<- train[,-2]
test<-X_test[,-8]

# na 가 있는 열 확인하기
colSums(is.na(train)) 
```

-   NA가 있는지 확인하기

```{r}
colSums(is.na(test))
```

-   NA가 있는 행 삭제하기

```{r}
# na 가 있는 열 제거하기
train<- train %>% na.omit()
test<- test %>% na.omit()
```

-   훈련용/검증용 데이터 나누기

```{r}
#훈련/검증 데이터  70:30 으로 나누기

idx<-createDataPartition(train$bill_depth, p=0.7, list=F)
train_df<-train[idx,]
test_df<-train[-idx,]
```

-   모델 만들고 학습시키기

```{r}
m1<-train(bill_depth~., data=train_df, method="glm") #로지스틱 회귀 모델

m2<-randomForest(bill_depth~., data=train_df, ntree=100) #랜덤포레스트 모델
```

-   학습된 모델로 예측하기

```{r}
p1<-predict(m1, test_df)

p2<-predict(m2, test_df)
```

-   모델 정합도 평가하기 (R\^2 로 판단)

```{r}
caret::R2(test_df$bill_depth, p1) #로지스틱 회귀분석
caret::R2(test_df$bill_depth, p2) #랜덤포레스트
```

-   최종모델로 모델링, 예측하기

```{r}
## 랜덤포레스트 모델로 최종 모델링 하기


m<-randomForest(bill_depth~., data=train, ntree=100)

p<-predict(m, test)
```

-   데이터 제출하기

```{r}
## p값을 문자열로 바꾸고 csv 파일로 제출하기

p<-as.character(p)
y_test$species <- p

write.csv(y_test, "1234.csv", row.names=F)


## 제출된 값 다시 한번 확인하기

abc<-read.csv("1234.csv")

head(abc)
```

### 회귀연습문제

-   중고차 가격 예측하기

\[DATA\]<https://www.kaggle.com/datasets/kukuroo3/used-car-price-dataset-competition-format/versions/1>

### 분류(Classification) : 펭귄종류

```         
1. penquin 데이터의 행번호를 id 열로 만들어라 (mutate)  

2. penquin 데이터의 1행~300행까지 데이터를 train으로 만들고, bill_depth 열을 제외하고 X_train, id와 bill_depth 열을 이용하여 y_train을 만들어라  

3. penquin 데이터의 300행~마지막행까지  데이터를 test 로 만들고, bill_depth 열을 제외하고 y_train, id와 bill_depth 열을 이용하여 y_test을 만들어라.     

4. X_train, y_train 으로 모델링을 한 후, X_test를 이용하여 y_test의 bill_depth를 예측하라.

5. 예측한 값을 "수험번호.csv" 파일로 제출하라.
```

-   패키지 불러오기

```{r}
library(dplyr)
library(caret)
library(ModelMetrics)
library(randomForest)

```

-   데이터 불러오기

```{r}
## 데이터 불러오기 (실제 시험장에서는 아래와 같이 간단하게 불러옴)

#X_train <- read.csv("../input/.../X_train.csv", stringsAsFactors=T)
#y_train <- read.csv("../input/.../y_train.csv", stringsAsFactors=T)

#X_test <- read.csv("../input/.../X_test.csv", stringsAsFactors=T)
#y_test <- read.csv("../input/.../y_test.csv", stringsAsFactors=T)

#penquin 데이터를 이용하여 데이터 train, test 데이터 만들기
rm(list=ls())
penguins <- penguins %>% mutate(id=1:nrow(penguins)) |> 
  rename(bill_depth = bill_depth_mm,
         bill_length = bill_length_mm ,
         flipper_length  = flipper_length_mm,
         body_mass  = body_mass_g )

X_train <- penguins[1:300, -1]
y_train <- penguins[1:300, c(1,9)]
X_test <- penguins[301:344, -1]
y_test <- penguins[301:344, c(1,9)]
y_test[,1] <- 0
```

-   데이터 합치기

```{r}
train<-inner_join(y_train, X_train, by="id")

str(train)
str(X_test)
```

-   불필요한 컬럼 제거하기

```{r}
# id 열 제거하기
train<- train[,-2]
test<-X_test[,-8]

# na 가 있는 열 확인하기
colSums(is.na(train)) 
colSums(is.na(test))

# na 가 있는 열 제거하기
train<- train %>% na.omit()
test<- test %>% na.omit()
```

-   훈련용/ 검증용 데이터 분리

```{r}
#훈련/검증 데이터  70:30 으로 나누기

idx<-createDataPartition(train$species, p=0.7, list=F)
train_df<-train[idx,]
test_df<-train[-idx,]
```

-   모델 만들기

```{r}
m1<-train(species~., data=train_df, method="rpart") #의사결정나무 모델

m2<-randomForest(species~., data=train_df, ntree=100) #랜덤포레스트 모델
```

-   예측하기

```{r}
p1<-predict(m1, test_df)

p2<-predict(m2, test_df)
```

-   모델 평가히기

```{r}
caret::confusionMatrix(test_df$species, p1)$overall[1] #의사결정나무/accuracy
caret::confusionMatrix(test_df$species, p1)$byClass[7] #의사결정나무/F1

caret::confusionMatrix(test_df$species, p2)$overall[1] #랜덤포레스트/accuracy
caret::confusionMatrix(test_df$species, p2)$byClass[7] #랜덤포레스트/F1
```

-   최종모델로 모델링, 예측하기

```{r}
## 랜덤포레스트 모델로 최종 모델링 하기


m<-randomForest(species~., data=train, ntree=100)

p<-predict(m, test)
```

-   데이터 제출하기

```{r}
## p값을 문자열로 바꾸고 csv 파일로 제출하기

p<-as.character(p)
y_test$species <- p


write.csv(y_test, "1234.csv", row.names=F)


## 제출된 값 다시 한번 확인하기 

abc<-read.csv("1234.csv")

head(abc)  
```

### 분류연습문제

-   이직할 사람 찾아내기

\[DATA\]<https://www.kaggle.com/datasets/kukuroo3/hr-data-predict-change-jobscompetition-form/versions/1>



#### 국회의원의석수 그래프

\[참고자료\]<https://r-charts.com/es/parte-todo/ggparliament/>

```{r}
# install.packages("ggparliament")
library(ggparliament)
# install.packages("tidyverse")
library(tidyverse)
# Datos
ru <- election_data %>%
  filter(country == "Russia" & year == 2016)
# Data frame a ser usado
ru_semicircle <- parliament_data(election_data = ru,
                                 type = "semicircle", # Tipo de parlamento
                                 parl_rows = 10,      # Número de filas del parlamento
                                 party_seats = ru$seats) # Asientos por partido

ggplot(ru_semicircle, aes(x = x, y = y, colour = party_short)) +
  geom_parliament_seats() + 
  theme_ggparliament() +
  labs(title = "Rusia, 2016") +
  scale_colour_manual(values = ru_semicircle$colour, 
                      limits = ru_semicircle$party_short)  
 
 
 

```

대한민국 22대 국회의원 의석수를 표시하시오 <https://open.assembly.go.kr/portal/assm/assmPartyNegotiationPage.do> \[color hexacode\]<https://htmlcolorcodes.com/>

```{r}


library(ggparliament)
df <- tibble::tribble(
  ~번호,   ~전국,       ~정당,   ~명,
   1L, "지역구",  "더불어민주당", 161L,
   2L, "지역구",    "국민의힘",  90L,
   3L, "지역구",   "새로운미래",   1L,
   4L, "지역구",    "개혁신당",   1L,
   5L, "지역구",     "진보당",   1L,
   6L,  "비례", "더불어민주연합",  14L,
   7L,  "비례",   "국민의미래",  18L,
   8L,  "비례",    "개혁신당",   2L,
   9L,  "비례",   "조국혁신당",  12L
  ) |> 
  mutate(no = c(1,3,4,2,9,6,7,8,5))

 

df_semicircle <- parliament_data(election_data = df,
                                 type = "semicircle", 
                                 parl_rows = 10,      
                                 party_seats = df$명) 


ggplot(df_semicircle, aes(x = x, y = y, colour =fct_reorder(정당, -명))) +
  geom_parliament_seats() + 
  theme_ggparliament() +
  labs(title = "South Korea, 2024") +
  scale_colour_manual(values = c("#0000FF", "#FF0000", 
                                 "#FF0000", "#0000FF", 
                                 "#0073CF", "#FFB233", 
                                 "#33FF42", "#E333FF"))


```
